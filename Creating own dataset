{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Creating own dataset","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNDxi0vbd5jNCznQYqPXl0n"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VdS4SY-nc18_","executionInfo":{"status":"ok","timestamp":1606812040171,"user_tz":480,"elapsed":37321,"user":{"displayName":"Taylor Yang","photoUrl":"","userId":"04111319468928325989"}},"outputId":"605edb82-74a9-406b-aa44-e77eb337c73e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J5Nl9atGf-1m"},"source":["import argparse\n","import os\n","img_width = 256\n","img_height = 128\n","img_channel = 3\n","label_width = 256\n","label_height = 128\n","label_channel = 1\n","data_loader_numworkers = 8\n","class_num = 2\n","val_path = 'val_data_0531.json'\n","train_path = 'all_label.json'\n","test_path = 'test_label.json'\n","\n","pretrained_path = ''\n","save_path = './Radam/' + pretrained_path[:12] + '/'\n","os.makedirs(save_path, exist_ok=True)\n","json_path = pretrained_path[:10] + '.json'\n","choose_path = './Radam/choose/'\n","os.makedirs(choose_path, exist_ok=True)\n","\n","class_weight = [0.146, 0.99]#\n","# class_weight = [0.2, 1.02]#\n","def args_setting():\n","    # Training settings\n","    parser = argparse.ArgumentParser(description='PyTorch UNet-ConvLSTM')\n","    parser.add_argument('--model',type=str, default='UNet_TwoConvGRU',help='( UNet-ConvLSTM | SegNet-ConvLSTM | UNet | SegNet | ')\n","    parser.add_argument('--batch-size', type=int, default=15, metavar='N',\n","                        help='input batch size for training (default: 10)')\n","    parser.add_argument('--test-batch-size', type=int, default=1, metavar='N',\n","                        help='input batch size for testing (default: 100)')\n","    parser.add_argument('--epochs', type=int, default=100, metavar='N',\n","                        help='number of epochs to train (default: 30)')\n","    parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n","                        help='learning rate (default: 0.01)')\n","    parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n","                        help='SGD momentum (default: 0.5)')\n","    parser.add_argument('--cuda', action='store_true', default=True,\n","                        help='use CUDA training')\n","    parser.add_argument('--seed', type=int, default=1, metavar='S',\n","                        help='random seed (default: 1)')\n","    parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n","                        help='how many batches to wait before logging training status')\n","    args = parser.parse_args()\n","    return args"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"id":"51iB4J7-f2aa","executionInfo":{"status":"error","timestamp":1606812875654,"user_tz":480,"elapsed":809,"user":{"displayName":"Taylor Yang","photoUrl":"","userId":"04111319468928325989"}},"outputId":"b35ca720-4106-411e-f39d-6cc6be266a7d"},"source":["import torch\n","import time\n","from shutil import copyfile\n","from dataset_new import RoadSequenceDataset, RoadSequenceDatasetList\n","import numpy as np\n","import cv2\n","from radam import RAdam\n","from model import UNet_TwoConvGRU\n","from torchvision import transforms\n","from torch.optim import lr_scheduler\n","current_pth_name = ''\n","import torch.nn.functional as F\n","best_acc = 0.903\n","best_name = config.pretrained_path\n","def train(args, epoch, model, train_loader, device, optimizer, criterion):\n","    since = time.time()\n","    model.train()\n","    for batch_idx,  sample_batched in enumerate(train_loader):\n","        data, target = sample_batched['data'].to(device), sample_batched['label'].type(torch.LongTensor).to(device) # LongTensor\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % args.log_interval == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))\n","\n","    time_elapsed = time.time() - since\n","    print('Train Epoch: {} complete in {:.0f}m {:.0f}s'.format(epoch,\n","        time_elapsed // 60, time_elapsed % 60))\n","\n","def val(args, model, val_loader, device, criterion, criterion2):\n","    model.eval()\n","    test_loss = 0\n","    test_loss2 = 0\n","    correct = 0\n","    i = 0\n","    with torch.no_grad():\n","        for sample_batched in val_loader:\n","            i += 1\n","            print('val--------------', i)\n","            data, target = sample_batched['data'].to(device), sample_batched['label'].type(torch.LongTensor).to(device)            \n","            output = model(data)\n","            test_loss += criterion(output, target).item()  # sum up batch loss\n","            pred = output.max(1, keepdim=True)[1]\n","            t = pred.eq(target.view_as(pred)).sum().item()\n","            correct += t\n","\n","    test_loss /= (len(val_loader.dataset)/args.test_batch_size)\n","    test_loss2 /= (len(val_loader.dataset) / args.test_batch_size)\n","    val_acc = 100. * int(correct) / (len(val_loader.dataset) * config.label_height * config.label_width)\n","    print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.5f}%)\\n'.format(test_loss, int(correct), len(val_loader.dataset), val_acc))\n","    current_pth_name = '%s.pth'%val_acc\n","    print('val-------current_pth_name---------------', current_pth_name)\n","    torch.save(model.state_dict(), '%s.pth'%val_acc)\n","    return current_pth_name\n","\n","\n","\n","def evaluate_model(model, test_loader, device, criterion):\n","    model.eval()\n","    i = 0\n","    precision = 0.0\n","    recall = 0.0\n","    test_loss = 0\n","    correct = 0\n","    error=0\n","    fp = 0\n","    fn = 0\n","    with torch.no_grad():\n","        for sample_batched in test_loader:\n","            i+=1\n","            print(i)\n","            data, target = sample_batched['data'].to(device), sample_batched['label'].type(torch.LongTensor).to(device)\n","            raw_file = sample_batched['raw_file']\n","            label_name = sample_batched['label_name']\n","            large_label = sample_batched['new_label']\n","            final_label = torch.squeeze(large_label).cpu().numpy() * 255\n","            s = time.time()\n","            output = model(data)\n","            e = time.time()\n","            pred = output.max(1, keepdim=True)[1]              \n","            img = torch.squeeze(pred).cpu().numpy()*255\n","            img2 = torch.squeeze(pred).cpu().unsqueeze(2).numpy() * 255\n","            final_img = cv2.resize(img2, (1280, 720), interpolation=cv2.INTER_NEAREST)\n","            lab = torch.squeeze(target).cpu().numpy()*255\n","            img = img.astype(np.uint8)#for pred_recall\n","            lab = lab.astype(np.uint8)#for label_precision\n","            kernel = np.uint8(np.ones((3, 3)))\n","            \n","            test_loss += criterion(output, target).item()  # sum up batch loss\n","            pred = output.max(1, keepdim=True)[1]\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","            label_precision = cv2.dilate(lab, kernel)\n","            # print('label_precision----', label_precision)\n","            pred_recall = cv2.dilate(img, kernel)\n","            # print('pred_recall----', pred_recall)\n","            img = img.astype(np.int32)\n","            lab = lab.astype(np.int32)\n","            label_precision = label_precision.astype(np.int32)\n","            pred_recall = pred_recall.astype(np.int32)\n","            # print('imge--------', img.shape, label_precision)\n","\n","            a = len(np.nonzero(img*label_precision)[1])\n","            b = len(np.nonzero(img)[1])\n","            if b==0:\n","                error=error+1\n","                continue\n","            else:\n","                fp += float(b - a)\n","                precision += float(a/b)\n","            c = len(np.nonzero(pred_recall*lab)[1])\n","            d = len(np.nonzero(lab)[1])\n","\n","            if d==0:\n","                error = error + 1\n","                continue\n","            else:\n","                fn += float(d - c)\n","                recall += float(c / d)\n","            F1_measure=(2*precision*recall)/(precision+recall)\n","    test_loss /= (len(test_loader.dataset) / args.test_batch_size)\n","    test_acc = 100. * int(correct) / (len(test_loader.dataset) * config.label_height * config.label_width)\n","    print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.5f}%)'.format(\n","        test_loss, int(correct), len(test_loader.dataset), test_acc))\n","\n","    precision = precision / (len(test_loader.dataset) - error)\n","    recall = recall / (len(test_loader.dataset) - error)\n","   \n","    F1_measure = F1_measure / (len(test_loader.dataset) - error)\n","    print('Precision: {:.5f}, Recall: {:.5f}, F1_measure: {:.5f}\\n'.format(precision,recall,F1_measure))\n","    evaluate_result = {'precision': precision, 'recall': recall, 'F1_measure': F1_measure, 'test_acc':test_acc}\n","    return evaluate_result\n","\n","\n","\n","    args = args_setting()\n","    torch.manual_seed(args.seed)\n","    use_cuda = args.cuda and torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    # turn image into floatTensor\n","    op_tranforms = transforms.Compose([transforms.ToTensor(),])\n","\n","    # load data for batches, num_workers for multiprocess\n","    train_loader = torch.utils.data.DataLoader(\n","        RoadSequenceDatasetList(file_path=config.train_path, transforms=op_tranforms),\n","        batch_size=args.batch_size, shuffle=True, num_workers=config.data_loader_numworkers)\n","    val_loader = torch.utils.data.DataLoader(\n","        RoadSequenceDatasetList(file_path=config.val_path, transforms=op_tranforms),\n","        batch_size=args.test_batch_size, shuffle=True, num_workers=config.data_loader_numworkers)\n","\n","    #load data for testing\n","    test_loader = torch.utils.data.DataLoader(\n","        RoadSequenceDataset(file_path=config.test_path, transforms=op_tranforms),\n","        batch_size=args.test_batch_size, shuffle=False, num_workers=1)\n","\n","    #load model\n","    model = UNet_TwoConvGRU(3, 2).to(device)\n","    # optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n","    # Adam 参数betas=(0.9, 0.99)\n","    #optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, betas=(0.9, 0.99))\n","    optimizer = RAdam(model.parameters(), lr=args.lr, betas=(0.9, 0.999))\n","    # optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=0.9)\n","\n","    scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n","    class_weight = torch.Tensor(config.class_weight)\n","    criterion = torch.nn.CrossEntropyLoss(weight=class_weight).to(device)\n","    criterion2 = torch.nn.MSELoss().to(device)\n","    # best_acc = 0\n","    if config.pretrained_path:\n","        print('loading------------------')\n","        pretrained_dict = torch.load(config.pretrained_path)\n","        model_dict = model.state_dict()\n","        #\n","        pretrained_dict_1 = {k: v for k, v in pretrained_dict.items() if (k in model_dict)}\n","        model_dict.update(pretrained_dict_1)\n","        model.load_state_dict(model_dict)\n","        evaluate_model(model, test_loader, device, criterion)\n","        exit(0)\n","    # train\n","    for epoch in range(1, args.epochs+1):\n","        if scheduler.get_lr()[0] > 0.0000001:\n","            scheduler.step()\n","        else:\n","            print('lr----no--change--------')\n","        print('lr---------', scheduler.get_lr())\n","        train(args, epoch, model, train_loader, device, optimizer, criterion)\n","        val_pth_name = val(args, model, val_loader, device, criterion, criterion2)\n","        print('val_pth_name------', val_pth_name)\n","        pretrained_dict = torch.load(val_pth_name)\n","        model_dict = model.state_dict()\n","        pretrained_dict_1 = {k: v for k, v in pretrained_dict.items() if (k in model_dict)}\n","        model_dict.update(pretrained_dict_1)\n","        model.load_state_dict(model_dict)\n","        result = evaluate_model(model, test_loader, device, criterion)\n","        if result['F1_measure'] > best_acc:\n","            best_acc = result['F1_measure']\n","            best_name='__test_acc=%s'%result['test_acc']  + '__precision=%s'%result['precision']  + '__recall=%s'%result['recall']  + '__F1_measure=%s'%result['F1_measure'] + '_epoch=%s'%epoch + '_'+ val_pth_name\n","            copyfile(val_pth_name, best_name)\n","            print('best testing-------------', best_name)\n","            print('test acc-------------',  result['test_acc'])\n","            print('precision-----------', result['precision'])\n","            print('recall-----------', result['recall'])\n","            print('F1_measure-----------', result['F1_measure'])\n","        elif result['F1_measure'] > 0.903:\n","            current_name='__test_acc=%s'%result['test_acc']  + '__precision=%s'%result['precision']  + '__recall=%s'%result['recall']  + '__F1_measure=%s'%result['F1_measure'] + '_epoch=%s'%epoch + '_'+ val_pth_name\n","            copyfile(val_pth_name, current_name)\n","            print('current testing-------------', val_pth_name)\n","            print('best testing-------------', best_name)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-7ca638b2dd88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mshutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopyfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset_new\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRoadSequenceDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRoadSequenceDatasetList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dataset_new'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"-UwZyiMSgaiN"},"source":[""],"execution_count":null,"outputs":[]}]}